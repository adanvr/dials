% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/parameters.R
\name{mtry}
\alias{mtry}
\alias{tree_parameters}
\alias{mtry_long}
\alias{trees}
\alias{min_n}
\alias{sample_size}
\alias{learn_rate}
\alias{loss_reduction}
\alias{tree_depth}
\alias{prune}
\alias{Cp}
\title{Parameter objects related to tree- and rule-based models.}
\usage{
mtry(range = c(1L, unknown()), trans = NULL)

mtry_long(range = c(0L, unknown()), trans = log10_trans())

trees(range = c(1L, 2000L), trans = NULL)

min_n(range = c(2L, unknown()), trans = NULL)

sample_size(range = c(unknown(), unknown()), trans = NULL)

learn_rate(range = c(unknown(), unknown()), trans = NULL)

loss_reduction(range = c(unknown(), unknown()), trans = NULL)

tree_depth(range = c(2L, 15L), trans = NULL)

prune(values = c(TRUE, FALSE))

Cp(range = c(-10, -1), trans = log10_trans())
}
\arguments{
\item{range}{A two-element vector holding the smallest and largest possible
values, respectively. If these cannot be set when the parameter is created,
\code{unknown()} can be used instead of a particular value. If a transformation
is specified, these should be in the \emph{transformed units}. The default is
an educated guess at the range of each parameter.}

\item{trans}{A \code{trans} object from the \code{scales} package, such as
\code{scales::log10_trans()} or \code{scales::reciprocal_trans()}. If not provided,
the default is used which matches the units used in \code{range}. If no
transformation, \code{NULL}.}

\item{values}{A vector of possible parameter values. For qualitative
parameters, character and logical defaults have been set, but can be modified
as needed.}
}
\value{
Each object is generated by either \code{new_quant_param()} or
\code{new_qual_param()}.
}
\description{
These are objects that can be used for modeling, especially in conjunction
with the \pkg{parsnip} package.
}
\details{
These objects are pre-made parameter sets that are useful when the model is
based on trees or rules.
\itemize{
\item \code{mtry()} and \code{mtry_long()}: The number of predictors that will be randomly
sampled at each split when creating the tree models. The latter uses a
log transformation and is helpful when the data set has a large number of
columns. \code{mtry()} is used by \pkg{parsnip}'s \code{parsnip::rand_forest()} function.
\item \code{trees()}: The number of trees contained in a random forest or boosted
ensemble. In the latter case, this is equal to the number of boosting
iterations. (see \code{parsnip::rand_forest()} and \code{parsnip::boost_tree()})
functions.
\item \code{min_n()}: The minimum number of data points in a node that are required
for the node to be split further. (\code{parsnip::rand_forest()} and
\code{parsnip::boost_tree()})
\item \code{sample_size()}: the size of the data set used for modeling within an
iteration of the modeling algorithm, such as stochastic gradient boosting.
(\code{parsnip::boost_tree()})
\item \code{learn_rate()}: the rate at which the boosting algorithm adapts from
iteration-to-iteration. (\code{parsnip::boost_tree()})
\item \code{loss_reduction()}:  The reduction in the loss function required to split
further. (\code{parsnip::boost_tree()})
\item \code{tree_depth()}: The maximum depth of the tree (i.e. number of splits).
(\code{parsnip::boost_tree()})
\item \code{prune()}: a logical for whether a tree or set of rules should be pruned.
\item \code{Cp()}: The cost-complexity parameter in classical CART models.
}
}
